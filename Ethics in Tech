Ethics in Tech

Ethical OS Toolkit
https://ethicalos.org

The thing that stuck out to me about this artical was that is a toolkit or checklist with 8 risk zones that help you identify the emerging areas of risk and social harm most critical for teams to consider noe. 14 secanarios to spark conversation and stretch imagination about long term impacts of tech that is bring built today.

I agree with this artical that things to look out for to keep the world a better place and make sure your software engineering isnt youve for evil include Risk Zone 1: Trust, Disinformation, Propaganda, Risk Zone 2 Addiction & the Dopamine Economy, Risk ZOne 3 Economic & Asset Inequalities, Risk Zone 4 Machine Ethics & Algorithmic Biases, Risk Zone 5 Surveillance State, Risk Zone 6 Data Control & Monetization, Risk Zone 7 Implicit Trust & User Understanding and Risk Zone 8 Hateful & Criminal Actors.

AI at Google
https://www.blog.google/technology/ai/ai-principles/

This article was all the greats things Google does for its users and the benefits on AI that learns and adapts to help solve some of the everyday problems possibly improving lives. Not only does Google invest heavily in AI research and development that make that much sought after research widely available to all through their tools and open-source code.

To ensure that with along with their gret power comes great responsibility that have adopted 7 principles to guide their work into te future with standards to govern their research and product development. Those include 1. Being socially beneficial, 2. Avoid creating or reinforcing unfair bias, 3. Be biult and tested for safety, 4. Be accountable to people, 5. Incorporate privacy design principles, 6. Uphold high standards of scientific excellence, 7. Be made available for uses that accord with these principles. Not only are those standards impressive that they also have a list of 4 AI applications that they will not pursue including 1. Technology that can cause or like to cause harm to others, 2. Weapons or other technologies with the principal purpose of implementation to cause injury to people, 3. Technology to gather or use surveillance violating internallly accepted norms and 4. Technology whose purpose contravenes widely accepted principles of international law and human rights. 
